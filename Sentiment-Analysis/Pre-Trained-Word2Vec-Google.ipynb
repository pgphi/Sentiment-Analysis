{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# About this Script"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This script creates word - vector pairs from the pre-trained word embeddings from the GoogleNews-vectors-negative300 dataset.\n",
    "Parameters of GoogleNews Word2Vec:\n",
    "- May used skip-gram-model \n",
    "- Dimensionality 300 (also most common [Mikolow et al. 2013; Yin & Shen, 2018])\n",
    "- However Mikolov mentioned in an interview, that he is not sure about exact parameters\n",
    "- Vocabularly size not known (however trained with appr. 100 billions words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('queen', 0.7118193507194519)]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('reputations', 0.7329850792884827),\n",
       " ('repuation', 0.6686696410179138),\n",
       " ('enviable_reputation', 0.6230523586273193),\n",
       " ('credibility', 0.6107540726661682),\n",
       " ('repute', 0.5464776754379272),\n",
       " ('renown', 0.5400000214576721),\n",
       " ('tarnished_reputation', 0.5282624363899231),\n",
       " ('prestige', 0.5186044573783875),\n",
       " ('fearsome_reputation', 0.5120456218719482),\n",
       " ('stature', 0.5068048238754272)]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from gensim.models import KeyedVectors\n",
    "\n",
    "filename = 'GoogleNews-vectors-negative300.bin'\n",
    "model = KeyedVectors.load_word2vec_format(filename, binary=True)\n",
    "\n",
    "# Getting familiar with model\n",
    "result = model.most_similar(positive=['woman', 'king'], negative=['man'], topn=1)\n",
    "print(result) # queen = king - man + woman (subtract manliness from king and add feminism to it --> you get the queen)\n",
    "model.most_similar(\"reputation\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Find similar words in word2vec and reviews and create word - vector pairs  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### [(\"review word\", word embedding vector from pre-trained word2vec)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tokenize text reviews\n",
    "from nltk.tokenize import word_tokenize\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('indeed_reviews_preprocessed_balanced.csv')\n",
    "review = df['review']\n",
    "review = review.str.cat(sep = \", \")\n",
    "review_tokens = word_tokenize(review)\n",
    "\n",
    "# create new dictionary of word - vector pairs of indeed reviews\n",
    "new_dict = {k: model[k] for k in review_tokens if k in model}\n",
    "\n",
    "# save learned word - vector pairs as csv\n",
    "pd.DataFrame(new_dict).to_csv('w2v_pre_trained_embeddings.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
