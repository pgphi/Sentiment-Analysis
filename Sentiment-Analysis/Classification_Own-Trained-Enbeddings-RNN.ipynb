{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "eba3e8f8",
   "metadata": {},
   "source": [
    "# About this Script"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "978751d6",
   "metadata": {},
   "source": [
    "A Recurrant Neural Network is implemented with the Keras and TensorFlow Framework, in order to create a model which predicts whether a view is labeled as positive (0) or negative (1). The models accuracy and f1-score is then evaluated and the accuracy and loss graphs ploted."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c5b9a08",
   "metadata": {},
   "source": [
    "##### Preparing Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a3812fda",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>company</th>\n",
       "      <th>review</th>\n",
       "      <th>rating</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>14502</th>\n",
       "      <td>university of leeds</td>\n",
       "      <td>Not a supportive workplace for BAME job candid...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18563</th>\n",
       "      <td>netsuite</td>\n",
       "      <td>I do get involved in many business and process...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9666</th>\n",
       "      <td>uchealth</td>\n",
       "      <td>I've worked here for over 3 years now. The ben...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16962</th>\n",
       "      <td>deloitte digital</td>\n",
       "      <td>One short sentence: No work/life balance!  To ...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2358</th>\n",
       "      <td>banco do brasil</td>\n",
       "      <td>Overall, work for Banco do Brasil is good for ...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   company                                             review  \\\n",
       "14502  university of leeds  Not a supportive workplace for BAME job candid...   \n",
       "18563             netsuite  I do get involved in many business and process...   \n",
       "9666              uchealth  I've worked here for over 3 years now. The ben...   \n",
       "16962     deloitte digital  One short sentence: No work/life balance!  To ...   \n",
       "2358       banco do brasil  Overall, work for Banco do Brasil is good for ...   \n",
       "\n",
       "       rating  sentiment  \n",
       "14502     3.0          1  \n",
       "18563     3.0          1  \n",
       "9666      3.0          1  \n",
       "16962     2.0          1  \n",
       "2358      4.0          0  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Basic packages\n",
    "import pandas as pd \n",
    "import numpy as np\n",
    "import re\n",
    "import collections\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "import time\n",
    "\n",
    "\n",
    "# Packages for data preparation\n",
    "from sklearn.model_selection import train_test_split\n",
    "from nltk.corpus import stopwords\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.utils.np_utils import to_categorical\n",
    "from keras import backend as K\n",
    "from keras.layers import Dropout\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "\n",
    "\n",
    "# Packages for modeling\n",
    "from keras import models\n",
    "from keras import layers\n",
    "from keras import regularizers\n",
    "from tensorflow.keras.layers import LSTM\n",
    "from keras import metrics\n",
    "from keras.utils.vis_utils import plot_model\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "\n",
    "\n",
    "df = pd.read_csv('indeed_reviews_preprocessed_balanced.csv')\n",
    "df = df.reindex(np.random.permutation(df.index)) \n",
    "df.head()\n",
    "\n",
    "# Reduce data_set for training\n",
    "# df = df[0:10000]\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7835959f",
   "metadata": {},
   "source": [
    "##### Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "10b1e355",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nDefinitions:\\n\\n- Epoch = One Epoch is when an ENTIRE dataset is passed forward and backward through the neural network only ONCE.\\n    - Small Epochs may lead to overfitting\\n    - Large Epochs may lead to underfitting\\n\\n- Batch = Total number of training examples present in a single batch. You can’t pass the entire dataset into the neural net at once. So, you divide dataset into Number of Batches or sets or parts.\\n    - Small values give a learning process that converges quickly at the cost of noise in the training process.\\n    - Large values give a learning process that converges slowly with accurate estimates of the error gradient.\\n'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "NB_WORDS = 1000 #initialized later with length of unique words in dataset. Indicating no. of most frequent words we keep.\n",
    "NB_START_EPOCHS = 25 # Number of epochs we start to train and plot accuracy and loss graphs\n",
    "EPOCH_ITER = range(1,11) # For evaluating the metrics for number of 10 epochs\n",
    "BATCH_SIZE = 32  # across a wide range of experiments the best results have been obtained with batch sizes m = 32 (Revisiting Small Batch Training for Deep Neural Networks, 2018)\n",
    "MAX_LEN = 260  # Maximum number of words in a sequence (review)\n",
    "REV_DIM = 256 # Number of dimensions of the indeed review word embeddings 256 rather common 300 hence power 2 computational power\n",
    "\n",
    "\n",
    "'''\n",
    "Definitions:\n",
    "\n",
    "- Epoch = One Epoch is when an ENTIRE dataset is passed forward and backward through the neural network only ONCE.\n",
    "    - Small Epochs may lead to overfitting\n",
    "    - Large Epochs may lead to underfitting\n",
    "\n",
    "- Batch = Total number of training examples present in a single batch. You can’t pass the entire dataset into the neural net at once. So, you divide dataset into Number of Batches or sets or parts.\n",
    "    - Small values give a learning process that converges quickly at the cost of noise in the training process.\n",
    "    - Large values give a learning process that converges slowly with accurate estimates of the error gradient.\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "798cce7f",
   "metadata": {},
   "source": [
    "##### Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cdc636b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper Functions\n",
    "\n",
    "# Compile and fit model\n",
    "def deep_model(model, X_train, y_train, X_valid, y_valid):\n",
    "    '''\n",
    "    Function to train a multi-class model. The number of epochs and \n",
    "    batch_size are set by the constants at the top of the\n",
    "    notebook. \n",
    "    \n",
    "    Parameters:\n",
    "        model : model with the chosen architecture\n",
    "        X_train : training features\n",
    "        y_train : training target\n",
    "        X_valid : validation features\n",
    "        Y_valid : validation target\n",
    "    Output:\n",
    "        model training history\n",
    "    '''\n",
    "    model.compile(optimizer='Adam'\n",
    "                  , loss='binary_crossentropy' # using binary_crossentropy since output is based on two labels\n",
    "                  , metrics=['acc',\n",
    "                             'FalseNegatives',\n",
    "                             'FalsePositives',\n",
    "                             'TrueNegatives',\n",
    "                             'TruePositives'\n",
    "                            ])\n",
    "    \n",
    "    history = model.fit(X_train\n",
    "                       , y_train\n",
    "                       , epochs=NB_START_EPOCHS\n",
    "                       , batch_size=BATCH_SIZE\n",
    "                       , validation_data=(X_valid, y_valid)\n",
    "                       , verbose=0)\n",
    "\n",
    "    return history\n",
    "\n",
    "\n",
    "# Plots the model training history for accuracy or loss (or any other metric_name)\n",
    "def eval_metric(history, metric_name):\n",
    "    '''\n",
    "    Function to evaluate a trained model on a chosen metric. \n",
    "    Training and validation metric are plotted in a\n",
    "    line chart for each epoch.\n",
    "    \n",
    "    Parameters:\n",
    "        history : model training history\n",
    "        metric_name : loss or accuracy\n",
    "    Output:\n",
    "        line chart with epochs of x-axis and metric on\n",
    "        y-axis\n",
    "    '''\n",
    "    metric = history.history[metric_name]\n",
    "    val_metric = history.history['val_' + metric_name]\n",
    "    \n",
    "    e = range(1, NB_START_EPOCHS + 1)\n",
    "\n",
    "    plt.plot(e, metric, 'bo', label='Train ' + metric_name)\n",
    "    plt.plot(e, val_metric, 'b', label='Validation ' + metric_name)\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "# Test model for i epochs iterations\n",
    "def test_model(model, X_train, y_train, X_test, y_test, epoch_stop):\n",
    "    '''\n",
    "    Function to test the model on new data after training it\n",
    "    on the full training data with the optimal number of epochs.\n",
    "    \n",
    "    Parameters:\n",
    "        model : trained model\n",
    "        X_train : training features\n",
    "        y_train : training target\n",
    "        X_test : test features\n",
    "        y_test : test target\n",
    "        epochs : optimal number of epochs\n",
    "    Output:\n",
    "        test accuracy and test loss\n",
    "    '''\n",
    "    model.fit(X_train\n",
    "            , y_train\n",
    "            , epochs=epoch_stop\n",
    "            , batch_size=BATCH_SIZE\n",
    "            , verbose=0)\n",
    "    results = model.evaluate(X_test, y_test)\n",
    "    \n",
    "    return results\n",
    "\n",
    "# Removing common stopwords\n",
    "def remove_stopwords(input_text):\n",
    "    '''\n",
    "    Function to remove English stopwords from a Pandas Series.\n",
    "    \n",
    "    Parameters:\n",
    "        input_text : text to clean\n",
    "    Output:\n",
    "        cleaned Pandas Series \n",
    "    '''\n",
    "    stopwords_list = stopwords.words('english')\n",
    "    # Some words which might indicate a certain sentiment are kept via a whitelist\n",
    "    whitelist = [\"n't\", \"not\", \"no\"]\n",
    "    words = input_text.split() \n",
    "    clean_words = [word for word in words if (word not in stopwords_list or word in whitelist) and len(word) > 1] \n",
    "    return \" \".join(clean_words) \n",
    "\n",
    "# Lemmatizaton and Tokenization\n",
    "def lem_and_tok(tokens):\n",
    "    le = WordNetLemmatizer()\n",
    "    lemmatized_tokens_empty = []\n",
    "    for word in tokens:\n",
    "        lemmatized_tokens = lemmatized_tokens_empty.append(le.lemmatize(word))\n",
    "    tokenizated = [[w for w in sentence.split(\" \") if w != \"\"] for sentence in tokens]\n",
    "    return tokenizated\n",
    "\n",
    "# returns text without special chars and punctuations\n",
    "def cleanText(text): \n",
    "    cleaned = re.sub(\"[^a-zA-Z0-9']\",\" \",text)\n",
    "    lowered = cleaned.lower()\n",
    "    return lowered.strip()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46362f64",
   "metadata": {},
   "source": [
    "###### Cleaning, Tokenization and initialize NB_WORDS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "98415245",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vocabularly size: 578111\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['not',\n",
       " 'supportive',\n",
       " 'workplace',\n",
       " 'bame',\n",
       " 'job',\n",
       " 'candidates',\n",
       " 'often',\n",
       " 'undervalued',\n",
       " 'underpaid',\n",
       " 'not']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.review = df.review.apply(remove_stopwords)\n",
    "\n",
    "review_to_array = np.asarray(df[\"review\"])\n",
    "review_cleaned = [cleanText(t) for t in review_to_array]\n",
    "# print(review_cleaned[0:2])\n",
    "\n",
    "# Tokenization\n",
    "cleaned_tokens = lem_and_tok(review_cleaned)\n",
    "\n",
    "# Merge clean tokens\n",
    "cleaned_tokens = [x for xs in cleaned_tokens for x in xs]\n",
    "\n",
    "# Initialize NB_WORDS\n",
    "cleaned_tokens_length = len(cleaned_tokens)\n",
    "print(\"vocabularly size: \" + str(cleaned_tokens_length))\n",
    "\n",
    "# Test\n",
    "# print(review_to_array[0])\n",
    "cleaned_tokens[0:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2548c965",
   "metadata": {},
   "source": [
    "##### Train and Test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "54053515",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Train data samples: 15395\n",
      "# Test data samples: 3849\n",
      "Value counts for Train sentiments\n",
      "1    7720\n",
      "0    7675\n",
      "Name: sentiment, dtype: int64\n",
      "Value counts for Test sentiments\n",
      "0    1947\n",
      "1    1902\n",
      "Name: sentiment, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(df.review, \n",
    "                                                    df.sentiment, \n",
    "                                                    test_size=0.2, \n",
    "                                                    random_state=42)\n",
    "\n",
    "print('# Train data samples:', X_train.shape[0])\n",
    "print('# Test data samples:', X_test.shape[0])\n",
    "print(\"Value counts for Train sentiments\")\n",
    "print(y_train.value_counts())\n",
    "print(\"Value counts for Test sentiments\")\n",
    "print(y_test.value_counts())\n",
    "assert X_train.shape[0] == y_train.shape[0] #Immidiately raise error when sets are not even\n",
    "assert X_test.shape[0] == y_test.shape[0] #Immidiately raise error when sets are not even\n",
    "\n",
    "# Test\n",
    "# print(X_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f9003b6",
   "metadata": {},
   "source": [
    "##### Converting Words to Vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0daba751",
   "metadata": {},
   "outputs": [],
   "source": [
    "tk = Tokenizer(num_words=NB_WORDS, \n",
    "               filters='!\"#$%&()*+,-./:;<=>?@[\\\\]^_`{|}~\\t\\n',\n",
    "               lower=True,\n",
    "               split=\" \")\n",
    "\n",
    "'''\n",
    "Tokenizer Updates internal vocabulary based on a list of texts. \n",
    "This method creates the vocabulary index based on word frequency.\n",
    "0 is reserved for padding. So lower integer means more frequent word\n",
    "'''\n",
    "\n",
    "tk.fit_on_texts(X_train)\n",
    "word_index = tk.word_index # assigns unique number to word\n",
    "# print(word_index)\n",
    "X_train_seq = tk.texts_to_sequences(X_train) # word_index\n",
    "X_test_seq = tk.texts_to_sequences(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e8f84b6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating word sequences of equal length\n",
    "seq_lengths = X_train.apply(lambda x: len(x.split(' ')))\n",
    "seq_lengths.describe() # set MAX_LENGTH (the review with the most words) to 'max' to avoid information loss \n",
    "# print(seq_lengths)\n",
    "\n",
    "# Padding\n",
    "X_train_seq_trunc = pad_sequences(X_train_seq, maxlen=MAX_LEN)\n",
    "X_test_seq_trunc = pad_sequences(X_test_seq, maxlen=MAX_LEN)\n",
    "# By that, no word truncating rather filling/padding reviews with 0, which don't fulfil max_length\n",
    "\n",
    "# X_train_seq_trunc[1]  # Example of padded sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "87dc7013",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converting target class to categorical float numbers\n",
    "le = LabelEncoder()\n",
    "y_train_le = le.fit_transform(y_train)\n",
    "y_test_le = le.transform(y_test)\n",
    "y_train_oh = to_categorical(y_train_le)\n",
    "y_test_oh = to_categorical(y_test_le)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "532bc50e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting of validation set\n",
    "X_train_emb, X_valid_emb, y_train_emb, y_valid_emb = train_test_split(X_train_seq_trunc, y_train_oh, test_size=0.2, random_state=42)\n",
    "\n",
    "assert X_valid_emb.shape[0] == y_valid_emb.shape[0]\n",
    "assert X_train_emb.shape[0] == y_train_emb.shape[0]\n",
    "\n",
    "# print('Shape of validation set:',X_valid_emb.shape)\n",
    "# print(X_train_emb.shape)\n",
    "# print(X_valid_emb.shape)\n",
    "# print(y_train_emb.shape)\n",
    "# print(y_valid_emb.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5d071cd",
   "metadata": {},
   "source": [
    "# Classifier (RNN)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09051b91",
   "metadata": {},
   "source": [
    "##### About this Recurrent Neural Network"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "baa4eff6",
   "metadata": {},
   "source": [
    "- Trained Embeddings based on own data suitable when just enough data for model (Qui et al., 2018). Further information about this model: Sequential API is used. Because it's most suitable for our problem. We neither have multiple inputs from different sources (only text data) nor have we multiple outputs (only two labels). \n",
    "<br>\n",
    "<br>\n",
    "- The first layer of our model is the Embedding Layer. There the feature vectors are generated. The Embedding layer has a size of input_dim x output_dim. Input_dim is the number of most instinct and common words in our case. The corpus has appr. 19000 words. So we want to keep half of those (8000), hence computational limits. The most common rule of thumb is 300 for the output_dim (e.g. Mikolow et al., 2013). However we seting size to 256 (2 to the power of 8) speeds up training time. Powers of 2 will increase cache utilization during data movement, thus reducing bottlenecks. We want to point out, that Patel & Bhattacharyya (2017) came up with a mathematical approach to calculate the best size for word embeddings ('lower bound'). The input length is equal to the MAX_LENGTH (in our case 260) of the sequence in order to avoid loss of information. \n",
    "<br>\n",
    "<br>\n",
    "- Next, we add the Long-Short-Term-Memory Layer (LSTM) Layer. This layer is very suitable for semantic parsing (Jia, Robin; Liang, Percy (2016). \"Data Recombination for Neural Semantic Parsing\". arXiv:1606.03622) and therefore also a good fit for our semantic-analyse. The rule of thumb for calculating the hidden nodes (number of neurons in the LSTM) is hidden_nodes := 2/3 * (timesteps * input_dim). In our case appr. 9000 hidden nodes would be needed (2/3 * 260 * 52). Because of computational reasons we only use half of the recommended hidden nodes (4500). Timesteps is the review with the most words (= max length of seq_lengths.describe() see code) which in our case is 260. For the hyperparameter input_dim, we choose 52. This equals all the lower and upper chars in the alphabet. If you have a higher number, the network gets more powerful. However, the number of parameters to learn also rises. This means it needs more time to train the network. Moreover, every LSTM layer should be accompanied by a Dropout layer. This layer will help to prevent overfitting by ignoring randomly selected neurons during training, and hence reduces the sensitivity to the specific weights of individual neurons. 20% is often used as a good compromise between retaining model accuracy and preventing overfitting. \n",
    "<br>\n",
    "<br>\n",
    "- Every LSTM layer should be accompanied by a Dropout layer. Dropout is a regularization technique for neural network models, against specialization proposed by Srivastava, et al., 2014. This layer will help to prevent overfitting by ignoring randomly selected neurons during training, and hence reduces the sensitivity to the specific weights of individual neurons. 20% is often used as a good compromise between retaining model accuracy and preventing overfitting. \n",
    "<br>\n",
    "<br>\n",
    "- The next layer is a BatchNormalization. Although there is a debate whether normalization is necessary, the authors of Batch Normalization say that it should be applied immediately before the non-linearity of the current layer (Hyv¨arinen & Oja, 2000). They say, that \"it is likely to produce activations with a stable distribution.\". Also Prof. Andrew Ng prefers to add the layer before nonlinearity (activation). \n",
    "<br>\n",
    "<br>\n",
    "- Lastly we add the Dense Layer, which is the most frequent layer. For the activation function we use softmax, because softmax assumes that each example is a member of exactly one class. This is suitable for our use case.\n",
    "<br>\n",
    "<br>\n",
    "- For the model we used the binary crossentropy and Adam optimizer, as well as the sigmoid activation function, hence the binary classification problem type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0b8fff8a",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Let the training begin..\n"
     ]
    },
    {
     "ename": "NotImplementedError",
     "evalue": "Cannot convert a symbolic Tensor (module_wrapper/lstm/strided_slice:0) to a numpy array. This error may indicate that you're trying to pass a Tensor to a NumPy call, which is not supported",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNotImplementedError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-0e418fbc44b4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0memb_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSequential\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0membeddings\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0memb_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mEmbedding\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mNB_WORDS\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mREV_DIM\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_length\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mMAX_LEN\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'embeddings'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0memb_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mLSTM\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m250\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_shape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mMAX_LEN\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m52\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# model.add(LSTM(hidden_nodes, input_shape=(timesteps, input_dim)))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0memb_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDropout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0.20\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/tensorflow/python/training/tracking/base.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    520\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_self_setattr_tracking\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    521\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 522\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    523\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    524\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_self_setattr_tracking\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprevious_value\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/keras/engine/sequential.py\u001b[0m in \u001b[0;36madd\u001b[0;34m(self, layer)\u001b[0m\n\u001b[1;32m    221\u001b[0m       \u001b[0;31m# If the model is being built continuously on top of an input layer:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    222\u001b[0m       \u001b[0;31m# refresh its output.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 223\u001b[0;31m       \u001b[0moutput_tensor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlayer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    224\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    225\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mSINGLE_LAYER_OUTPUT_ERROR_MSG\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    943\u001b[0m     \u001b[0;31m# >> model = tf.keras.Model(inputs, outputs)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    944\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0m_in_functional_construction_mode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 945\u001b[0;31m       return self._functional_construction_call(inputs, args, kwargs,\n\u001b[0m\u001b[1;32m    946\u001b[0m                                                 input_list)\n\u001b[1;32m    947\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m_functional_construction_call\u001b[0;34m(self, inputs, args, kwargs, input_list)\u001b[0m\n\u001b[1;32m   1081\u001b[0m         layer=self, inputs=inputs, build_graph=True, training=training_value):\n\u001b[1;32m   1082\u001b[0m       \u001b[0;31m# Check input assumptions set after layer building, e.g. input shape.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1083\u001b[0;31m       outputs = self._keras_tensor_symbolic_call(\n\u001b[0m\u001b[1;32m   1084\u001b[0m           inputs, input_masks, args, kwargs)\n\u001b[1;32m   1085\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m_keras_tensor_symbolic_call\u001b[0;34m(self, inputs, input_masks, args, kwargs)\u001b[0m\n\u001b[1;32m    814\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap_structure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkeras_tensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mKerasTensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_signature\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    815\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 816\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_infer_output_signature\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_masks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    817\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    818\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_infer_output_signature\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_masks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m_infer_output_signature\u001b[0;34m(self, inputs, args, kwargs, input_masks)\u001b[0m\n\u001b[1;32m    854\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_build\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    855\u001b[0m           \u001b[0minputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_cast_inputs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 856\u001b[0;31m           \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcall_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    857\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    858\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle_activity_regularization\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/keras/engine/functional.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1440\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;34m'mask'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_expects_mask_arg\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1441\u001b[0m       \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'mask'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1442\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_module\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_method_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/tensorflow/python/keras/layers/recurrent.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs, initial_state, constants, **kwargs)\u001b[0m\n\u001b[1;32m    666\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    667\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0minitial_state\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mconstants\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 668\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mRNN\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    669\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    670\u001b[0m     \u001b[0;31m# If any of `initial_state` or `constants` are specified and are Keras\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/tensorflow/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1028\u001b[0m         with autocast_variable.enable_auto_cast_variables(\n\u001b[1;32m   1029\u001b[0m             self._compute_dtype_object):\n\u001b[0;32m-> 1030\u001b[0;31m           \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcall_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1031\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1032\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_activity_regularizer\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/tensorflow/python/keras/layers/recurrent_v2.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, inputs, mask, training, initial_state)\u001b[0m\n\u001b[1;32m   1151\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1152\u001b[0m     \u001b[0;31m# LSTM does not support constants. Ignore it during process.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1153\u001b[0;31m     \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minitial_state\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_process_inputs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minitial_state\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1154\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1155\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/tensorflow/python/keras/layers/recurrent.py\u001b[0m in \u001b[0;36m_process_inputs\u001b[0;34m(self, inputs, initial_state, constants)\u001b[0m\n\u001b[1;32m    866\u001b[0m         \u001b[0minitial_state\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstates\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    867\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0minitial_state\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 868\u001b[0;31m       \u001b[0minitial_state\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_initial_state\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    869\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    870\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minitial_state\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/tensorflow/python/keras/layers/recurrent.py\u001b[0m in \u001b[0;36mget_initial_state\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m    648\u001b[0m     \u001b[0mdtype\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    649\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mget_initial_state_fn\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 650\u001b[0;31m       init_state = get_initial_state_fn(\n\u001b[0m\u001b[1;32m    651\u001b[0m           inputs=None, batch_size=batch_size, dtype=dtype)\n\u001b[1;32m    652\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/tensorflow/python/keras/layers/recurrent.py\u001b[0m in \u001b[0;36mget_initial_state\u001b[0;34m(self, inputs, batch_size, dtype)\u001b[0m\n\u001b[1;32m   2514\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2515\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mget_initial_state\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2516\u001b[0;31m     return list(_generate_zero_filled_state_for_cell(\n\u001b[0m\u001b[1;32m   2517\u001b[0m         self, inputs, batch_size, dtype))\n\u001b[1;32m   2518\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/tensorflow/python/keras/layers/recurrent.py\u001b[0m in \u001b[0;36m_generate_zero_filled_state_for_cell\u001b[0;34m(cell, inputs, batch_size, dtype)\u001b[0m\n\u001b[1;32m   2996\u001b[0m     \u001b[0mbatch_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0marray_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2997\u001b[0m     \u001b[0mdtype\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2998\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0m_generate_zero_filled_state\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcell\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2999\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3000\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/tensorflow/python/keras/layers/recurrent.py\u001b[0m in \u001b[0;36m_generate_zero_filled_state\u001b[0;34m(batch_size_tensor, state_size, dtype)\u001b[0m\n\u001b[1;32m   3012\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3013\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mnest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_nested\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3014\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mnest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap_structure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcreate_zeros\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstate_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3015\u001b[0m   \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3016\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mcreate_zeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/tensorflow/python/util/nest.py\u001b[0m in \u001b[0;36mmap_structure\u001b[0;34m(func, *structure, **kwargs)\u001b[0m\n\u001b[1;32m    865\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    866\u001b[0m   return pack_sequence_as(\n\u001b[0;32m--> 867\u001b[0;31m       \u001b[0mstructure\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mentries\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    868\u001b[0m       expand_composites=expand_composites)\n\u001b[1;32m    869\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/tensorflow/python/util/nest.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    865\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    866\u001b[0m   return pack_sequence_as(\n\u001b[0;32m--> 867\u001b[0;31m       \u001b[0mstructure\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mentries\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    868\u001b[0m       expand_composites=expand_composites)\n\u001b[1;32m    869\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/tensorflow/python/keras/layers/recurrent.py\u001b[0m in \u001b[0;36mcreate_zeros\u001b[0;34m(unnested_state_size)\u001b[0m\n\u001b[1;32m   3009\u001b[0m     \u001b[0mflat_dims\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtensor_shape\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensorShape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0munnested_state_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3010\u001b[0m     \u001b[0minit_state_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mbatch_size_tensor\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mflat_dims\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3011\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0marray_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minit_state_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3012\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3013\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mnest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_nested\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/tensorflow/python/util/dispatch.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    204\u001b[0m     \u001b[0;34m\"\"\"Call target, and fall back on dispatchers if there is a TypeError.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    205\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 206\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    207\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mTypeError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    208\u001b[0m       \u001b[0;31m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/tensorflow/python/ops/array_ops.py\u001b[0m in \u001b[0;36mwrapped\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m   2909\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2910\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mwrapped\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2911\u001b[0;31m     \u001b[0mtensor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2912\u001b[0m     \u001b[0mtensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_is_zeros_tensor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2913\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mtensor\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/tensorflow/python/ops/array_ops.py\u001b[0m in \u001b[0;36mzeros\u001b[0;34m(shape, dtype, name)\u001b[0m\n\u001b[1;32m   2958\u001b[0m           \u001b[0;31m# Create a constant if it won't be very big. Otherwise create a fill\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2959\u001b[0m           \u001b[0;31m# op to prevent serialized GraphDefs from becoming too large.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2960\u001b[0;31m           \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_constant_if_small\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mzero\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2961\u001b[0m           \u001b[0;32mif\u001b[0m \u001b[0moutput\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2962\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/tensorflow/python/ops/array_ops.py\u001b[0m in \u001b[0;36m_constant_if_small\u001b[0;34m(value, shape, dtype, name)\u001b[0m\n\u001b[1;32m   2894\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_constant_if_small\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2895\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2896\u001b[0;31m     \u001b[0;32mif\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m1000\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2897\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mconstant\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2898\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<__array_function__ internals>\u001b[0m in \u001b[0;36mprod\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/numpy/core/fromnumeric.py\u001b[0m in \u001b[0;36mprod\u001b[0;34m(a, axis, dtype, out, keepdims, initial, where)\u001b[0m\n\u001b[1;32m   3028\u001b[0m     \u001b[0;36m10\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3029\u001b[0m     \"\"\"\n\u001b[0;32m-> 3030\u001b[0;31m     return _wrapreduction(a, np.multiply, 'prod', axis, dtype, out,\n\u001b[0m\u001b[1;32m   3031\u001b[0m                           keepdims=keepdims, initial=initial, where=where)\n\u001b[1;32m   3032\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/numpy/core/fromnumeric.py\u001b[0m in \u001b[0;36m_wrapreduction\u001b[0;34m(obj, ufunc, method, axis, dtype, out, **kwargs)\u001b[0m\n\u001b[1;32m     85\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mreduction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mpasskwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     86\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 87\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mufunc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreduce\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mpasskwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     88\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     89\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36m__array__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    865\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    866\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m__array__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 867\u001b[0;31m     raise NotImplementedError(\n\u001b[0m\u001b[1;32m    868\u001b[0m         \u001b[0;34m\"Cannot convert a symbolic Tensor ({}) to a numpy array.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    869\u001b[0m         \u001b[0;34m\" This error may indicate that you're trying to pass a Tensor to\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNotImplementedError\u001b[0m: Cannot convert a symbolic Tensor (module_wrapper/lstm/strided_slice:0) to a numpy array. This error may indicate that you're trying to pass a Tensor to a NumPy call, which is not supported"
     ]
    }
   ],
   "source": [
    "# Specify Model\n",
    "print(\"Let the training begin..\")\n",
    "start_time = time.time()\n",
    "\n",
    "emb_model = models.Sequential()\n",
    "embeddings = emb_model.add(layers.Embedding(NB_WORDS, REV_DIM, input_length=MAX_LEN, name='embeddings')) \n",
    "emb_model.add(LSTM(250, input_shape=(MAX_LEN,52))) # model.add(LSTM(hidden_nodes, input_shape=(timesteps, input_dim)))\n",
    "emb_model.add(Dropout(0.20))\n",
    "\n",
    "'''\n",
    "To reduce overfitting, the dropout layer just randomly \n",
    "takes a portion of the possible network connections. \n",
    "This value is the percentage of the considered network \n",
    "connections per epoch/batch.\n",
    "'''\n",
    "\n",
    "emb_model.add(BatchNormalization())\n",
    "emb_model.add(layers.Dense(2, activation='sigmoid'))\n",
    "\n",
    "print(\"Training the Model took: \" + \"{}\".format(time.time()-start_time) + \" seconds\" + \"\\n\")\n",
    "\n",
    "# Print Model Overview\n",
    "emb_model.summary()\n",
    "plot_model(emb_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12f95dbc",
   "metadata": {},
   "source": [
    "**Note - to avoid NotimplementedError (if raised):**\n",
    "<br>\n",
    "\"Cannot convert a symbolic Tensor (module_wrapper_8/lstm_8/strided_slice:0) \n",
    "to a numpy array. This error may indicate that you're trying to pass a Tensor \n",
    "to a NumPy call, which is not supported\" --> downgrade numpy package (install numpy == 1.19.5)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09b98b55",
   "metadata": {},
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "c6e6cfed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trained model has an accuracy of 0.9840624928474426\n"
     ]
    }
   ],
   "source": [
    "emb_history = deep_model(emb_model, X_train_emb, y_train_emb, X_valid_emb, y_valid_emb)\n",
    "train_acc = emb_history.history['acc'][-1]\n",
    "print(\"Trained model has an accuracy of \" + str(train_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "fd8b8f03",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "eval_metric(emb_history, 'acc')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f07dbb6",
   "metadata": {},
   "source": [
    "**Interpretation:**\n",
    "- Increasing training accuracy, but decreasing validation accuracy. The larger the gap, the higher is overfitting and specialization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "6beb7372",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "eval_metric(emb_history, 'loss')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a0fb230",
   "metadata": {},
   "source": [
    "**Interpretation:**\n",
    "- The training loss keeps decreasing after every epoch. Our model is learning to recognize the specific reviews in the training set.\n",
    "    \n",
    "- The validation loss keeps increasing after every epoch. Our model is not generalizing well enough on the  validation set, however a drop is seen right at epoch 50. More epoch iterations may result in decrease in validation loss\n",
    "\n",
    "- A good fit is identified by a training and validation loss that decreases to a point of stability with a           minimal gap between the two final loss values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "18dae565",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 Epoch(s): \n",
      "\n",
      "63/63 [==============================] - 10s 148ms/step - loss: 0.7979 - acc: 0.7245\n",
      "\n",
      "\n",
      "2 Epoch(s): \n",
      "\n",
      "63/63 [==============================] - 8s 128ms/step - loss: 1.0651 - acc: 0.7190\n",
      "\n",
      "\n",
      "3 Epoch(s): \n",
      "\n",
      "63/63 [==============================] - 10s 161ms/step - loss: 1.2180 - acc: 0.7175\n",
      "\n",
      "\n",
      "4 Epoch(s): \n",
      "\n",
      "63/63 [==============================] - 8s 131ms/step - loss: 1.5451 - acc: 0.7135\n",
      "\n",
      "\n",
      "5 Epoch(s): \n",
      "\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-168-3d692cc14bfc>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mEPOCH_ITER\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'{} Epoch(s): '\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mEPOCH_ITER\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'\\n'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0memb_results\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0memb_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_train_seq_trunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train_oh\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_test_seq_trunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test_oh\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mEPOCH_ITER\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'\\n'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-157-de24890d02ba>\u001b[0m in \u001b[0;36mtest_model\u001b[0;34m(model, X_train, y_train, X_test, y_test, epoch_stop)\u001b[0m\n\u001b[1;32m     76\u001b[0m         \u001b[0mtest\u001b[0m \u001b[0maccuracy\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mtest\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     77\u001b[0m     '''\n\u001b[0;32m---> 78\u001b[0;31m     model.fit(X_train\n\u001b[0m\u001b[1;32m     79\u001b[0m             \u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     80\u001b[0m             \u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mepoch_stop\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1156\u001b[0m                 _r=1):\n\u001b[1;32m   1157\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1158\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1159\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1160\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    887\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 889\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    890\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    891\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    915\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    916\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 917\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    918\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    919\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   3021\u001b[0m       (graph_function,\n\u001b[1;32m   3022\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[0;32m-> 3023\u001b[0;31m     return graph_function._call_flat(\n\u001b[0m\u001b[1;32m   3024\u001b[0m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[1;32m   3025\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1958\u001b[0m         and executing_eagerly):\n\u001b[1;32m   1959\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1960\u001b[0;31m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0m\u001b[1;32m   1961\u001b[0m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[1;32m   1962\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    589\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0m_InterpolateFunctionError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    590\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcancellation_manager\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 591\u001b[0;31m           outputs = execute.execute(\n\u001b[0m\u001b[1;32m    592\u001b[0m               \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msignature\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    593\u001b[0m               \u001b[0mnum_outputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_outputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     57\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 59\u001b[0;31m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[1;32m     60\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for i in EPOCH_ITER:   \n",
    "    print('{} Epoch(s): '.format(EPOCH_ITER[i-1]) + '\\n')\n",
    "    emb_results = test_model(emb_model, X_train_seq_trunc, y_train_oh, X_test_seq_trunc, y_test_oh, EPOCH_ITER[i-1])\n",
    "    print('\\n')\n",
    "\n",
    "    \n",
    "'''\n",
    "Methods for pruning the model:\n",
    "- Reduce the learning rate to a very small number (e.g. 0.001 or even 0.0001).\n",
    "- Provide more data.\n",
    "- Set more dropout rates to a number like 0.2 & keep them uniform across the network (further see Srivastava, et al., 2014.)\n",
    "- Try decreasing the batch size.\n",
    "- Using appropriate optimizer: You may need to experiment a bit on this. Use different optimizers on the same network, and select an optimizer which gives you the least loss.\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4873c85",
   "metadata": {},
   "source": [
    "**Interpretation:**\n",
    "- Loss is increasing after 1 epoch (79,79%), accuracy is decreasing after 1 epoch (72,54%). One epoch should be used for initializing the model, hence avoiding specialization. (10000 reviews and 301355 words.)\n",
    "<br>\n",
    "<br>\n",
    "- ..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d80cc754",
   "metadata": {},
   "source": [
    "# Save embeddings learned by model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab4340af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save embeddings\n",
    "embeddings = emb_model.get_layer('embeddings').get_weights()[0]\n",
    "my_w2v = {}\n",
    "\n",
    "for word, index in tk.word_index.items():\n",
    "    my_w2v[word] = embeddings[index]\n",
    "\n",
    "# print(w2v_my['company'])\n",
    "first2pairs = {k: my_w2v[k] for k in list(my_w2v)[:2]}\n",
    "# print(first2pairs)\n",
    "\n",
    "my_w2v_df = pd.DataFrame(my_w2v)\n",
    "# my_w2v_df.to_csv(\"own_trained_word_embeddings\")\n",
    "my_w2v_df.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
